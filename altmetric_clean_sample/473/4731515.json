{"altmetric_id":4731515,"counts":{"readers":{"mendeley":12,"citeulike":0,"connotea":0},"total":{"posts_count":2},"twitter":{"unique_users_count":2,"unique_users":["uranus_2","motioninsocial"],"posts_count":2}},"selected_quotes":["Our stimuli set of #emotional #multisensory #social point-light displays, now published in Behavior Research Methods"],"citation":{"abstract":"We describe the creation of the first multisensory stimulus set that consists of dyadic, emotional, point-light interactions combined with voice dialogues. Our set includes 238 unique clips, which present happy, angry and neutral emotional interactions at low, medium and high levels of emotional intensity between nine different actor dyads. The set was evaluated in a between-design experiment, and was found to be suitable for a broad potential application in the cognitive and neuroscientific study of biological motion and voice, perception of social interactions and multisensory integration. We also detail in this paper a number of supplementary materials, comprising AVI movie files for each interaction, along with text files specifying the three dimensional coordinates of each point-light in each frame of the movie, as well as unprocessed AIFF audio files for each dialogue captured. The full set of stimuli is available to download from: http:\/\/motioninsocial.com\/stimuli_set\/ .","altmetric_jid":"4f6fa4e93cf058f61000239d","authors":["Lukasz Piwek","Karin Petrini","Frank Pollick","Piwek, Lukasz","Petrini, Karin","Pollick, Frank"],"doi":"10.3758\/s13428-015-0654-4","first_seen_on":"2015-11-06T09:00:38+00:00","funders":["niehs"],"issns":["1554-3528"],"journal":"Behavior Research Methods","last_mentioned_on":1447080490,"links":["http:\/\/link.springer.com\/article\/10.3758\/s13428-015-0654-4","http:\/\/link.springer.com\/article\/10.3758\/s13428-015-0654-4?wt_mc=internal.event.1.SEM.ArticleAuthorOnlineFirst"],"pdf_url":"http:\/\/link.springer.com\/content\/pdf\/10.3758%2Fs13428-015-0654-4.pdf","pmid":"26542970","pubdate":"2015-11-05T00:00:00+00:00","publisher":"Springer US","publisher_subjects":[{"name":"Artificial Intelligence And Image Processing","scheme":"era"},{"name":"Cognitive Science","scheme":"era"},{"name":"Psychology","scheme":"era"}],"scopus_subjects":["Social Sciences","Psychology"],"subjects":["behavioralsciences"],"title":"A dyadic stimulus set of audiovisual affective displays for the study of multisensory, emotional, social interactions","type":"article","uri":"http:\/\/link.springer.com\/10.3758\/s13428-015-0654-4","mendeley_url":"http:\/\/www.mendeley.com\/research\/dyadic-stimulus-set-audiovisual-affective-displays-study-multisensory-emotional-social-interactions"},"altmetric_score":{"score":1.25,"score_history":{"1y":0,"6m":0,"3m":0,"1m":0,"1w":0,"6d":0,"5d":0,"4d":0,"3d":0,"2d":0,"1d":0,"at":1.25},"context_for_score":{"all":{"total_number_of_other_articles":6549866,"mean":6.0697548813592,"rank":2908917,"this_scored_higher_than_pct":52,"this_scored_higher_than":3465318,"rank_type":"exact","sample_size":6549866,"percentile":52},"similar_age_3m":{"total_number_of_other_articles":210184,"mean":10.2627897594,"rank":103256,"this_scored_higher_than_pct":46,"this_scored_higher_than":98170,"rank_type":"exact","sample_size":210184,"percentile":46},"this_journal":{"total_number_of_other_articles":597,"mean":4.0744530201342,"rank":250,"this_scored_higher_than_pct":54,"this_scored_higher_than":325,"rank_type":"exact","sample_size":597,"percentile":54},"similar_age_this_journal_3m":{"total_number_of_other_articles":34,"mean":14.062,"rank":15,"this_scored_higher_than_pct":47,"this_scored_higher_than":16,"rank_type":"exact","sample_size":34,"percentile":47}}},"demographics":{"poster_types":{"member_of_the_public":2},"users":{"twitter":{"cohorts":{"Members of the public":2}},"mendeley":{"by_status":{"Researcher":2,"Student  > Doctoral Student":2,"Student  > Ph. D. Student":3,"Student  > Master":2,"Student  > Bachelor":1,"Lecturer":1,"Lecturer > Senior Lecturer":1},"by_discipline":{"Neuroscience":2,"Psychology":8,"Computer Science":1,"Unspecified":1}}},"geo":{"twitter":{"GB":1},"mendeley":{"GB":1}}},"posts":{"twitter":[{"url":"http:\/\/twitter.com\/uranus_2\/statuses\/662555114146672640","license":"gnip","citation_ids":[4731515],"posted_on":"2015-11-06T09:00:23+00:00","author":{"name":"\u30de\u30fc\u30ad\u30e5\u30ea\u30fc\uff12\u4e16","url":"http:\/\/smetc.blog120.fc2.com\/?sp","image":"https:\/\/pbs.twimg.com\/profile_images\/650483455248064512\/EOJq3sZX_normal.png","description":"\u5c11\u306a\u304f\u3068\u3082\u5927\u5b66\u521d\u5e74\u6b21\u307e\u3067\u306f\u5834\u9762\u7dd8\u9ed9\u75c7\uff08\u81ea\u5df1\u8a3a\u65ad\uff09\u3060\u3063\u305f\u7537\u3002Twitter\u307e\u3068\u3081(http:\/\/psychobrain.seesaa.net\/)\u3002 \u6ce8\u610f\u4e8b\u9805\u2460\u8ad6\u6587\u306f\u8981\u7d04\u3057\u304b\u8aad\u3093\u3067\u3044\u306a\u3044\u5834\u5408\u304c\u591a\u3044\u2461\u9593\u9055\u3063\u3066\u3044\u308b\u53ef\u80fd\u6027\u3042\u308a\u2462\u79c1\u306f\u7814\u7a76\u8005\u3067\u306f\u306a\u3044\u3002","id_on_source":"uranus_2","tweeter_id":"253847599","geo":{"lt":null,"ln":null},"followers":3450},"tweet_id":"662555114146672640"},{"url":"http:\/\/twitter.com\/motioninsocial\/statuses\/663729800364863488","license":"gnip","citation_ids":[4731515],"posted_on":"2015-11-09T14:48:10+00:00","author":{"name":"Dr Lukasz Piwek","url":"http:\/\/www.lukaszpiwek.com","image":"https:\/\/pbs.twimg.com\/profile_images\/1631164764\/IMG_2390_normal.JPG","description":"Lecturer in Data Science @UniofBath. Big [Behavioural] Data; Behavioural Profiling; Cyberpsychology; Computational Social Science; Minimalistic Data Viz; R.","id_on_source":"motioninsocial","tweeter_id":"272383136","geo":{"lt":51.45523,"ln":-2.59665,"country":"GB"},"followers":681},"tweet_id":"663729800364863488"}]}}