{"altmetric_id":26572550,"counts":{"readers":{"mendeley":5,"citeulike":0,"connotea":0},"total":{"posts_count":14},"twitter":{"unique_users_count":11,"unique_users":["StatMLPapers","gngdb_rss_bot","helioRocha_","ibiris","SoEngineering","dbworld_","deep_rl","StatsPapers","arxivml","arxiv_flying","muktabh"],"posts_count":13},"reddit":{"unique_users_count":1,"unique_users":["PM_ME_FRENCH_WORDS"],"posts_count":1}},"selected_quotes":["An Optimal Online Method of Selecting Source Policies for Reinforcement Learning, Siyuan Li, Chongjie Zhang","An Optimal Online Method of Selecting Source Policies for Reinforcement Learning. (arXiv:1709.08201v1 ) #ai","An Optimal Online Method of Selecting Source Policies for Reinforcement Learning. (arXiv:1709.08201v1 )"],"citation":{"altmetric_jid":"arxiv","arxiv_id":"1709.08201","authors":["Siyuan Li","Chongjie Zhang"],"first_seen_on":"2017-09-26T01:13:36+00:00","issns":[],"journal":"arXiv","last_mentioned_on":1506483190,"links":["https:\/\/arxiv.org\/abs\/1709.08201","https:\/\/arxiv.org\/abs\/1709.08201v1"],"pdf_url":"http:\/\/arxiv.org\/pdf\/1709.08201v1","pubdate":"2017-09-24T14:17:14+00:00","title":"An Optimal Online Method of Selecting Source Policies for Reinforcement\n  Learning","type":"article","mendeley_url":"http:\/\/www.mendeley.com\/research\/optimal-online-method-selecting-source-policies-reinforcement-learning"},"altmetric_score":{"score":3,"score_history":{"1y":3,"6m":3,"3m":3,"1m":3,"1w":1.75,"6d":0.25,"5d":0,"4d":0,"3d":0,"2d":0,"1d":0,"at":3},"context_for_score":{"all":{"total_number_of_other_articles":8462170,"mean":7.1084920520889,"rank":2177564,"this_scored_higher_than_pct":60,"this_scored_higher_than":5131925,"rank_type":"exact","sample_size":8462170,"percentile":60},"similar_age_3m":{"total_number_of_other_articles":114580,"mean":11.47238802922,"rank":34859,"this_scored_higher_than_pct":68,"this_scored_higher_than":78992,"rank_type":"exact","sample_size":114580,"percentile":68},"this_journal":{"total_number_of_other_articles":476038,"mean":2.8046109861209,"rank":62288,"this_scored_higher_than_pct":86,"this_scored_higher_than":409422,"rank_type":"exact","sample_size":476038,"percentile":86},"similar_age_this_journal_3m":{"total_number_of_other_articles":16020,"mean":2.9704465946688,"rank":1972,"this_scored_higher_than_pct":86,"this_scored_higher_than":13922,"rank_type":"exact","sample_size":16020,"percentile":86}}},"demographics":{"poster_types":{"member_of_the_public":10,"researcher":1},"users":{"twitter":{"cohorts":{"Members of the public":10,"Scientists":1}},"mendeley":{"by_status":{"Professor":1,"Other":1,"Student  > Master":2,"Unspecified":1},"by_discipline":{"Computer Science":5}}},"geo":{"twitter":{"FI":1,"DE":1,"IN":1}}},"posts":{"twitter":[{"url":"http:\/\/twitter.com\/StatMLPapers\/statuses\/912485226529648647","license":"gnip","citation_ids":[26572550],"posted_on":"2017-09-26T01:13:25+00:00","author":{"name":"Stat.ML Papers","url":"http:\/\/arxiv.org\/list\/stat.ML\/recent","image":"https:\/\/pbs.twimg.com\/profile_images\/2279093116\/2th9zk669cyw0i90g4ew_normal.png","description":"Unofficial updates of statistical machine learning papers on arXiv","id_on_source":"StatMLPapers","tweeter_id":"599628731","geo":{"lt":null,"ln":null},"followers":5109},"tweet_id":"912485226529648647"},{"url":"http:\/\/twitter.com\/gngdb_rss_bot\/statuses\/912485339280941056","license":"gnip","citation_ids":[26572550],"posted_on":"2017-09-26T01:13:52+00:00","author":{"name":"gngdb rss bot","image":"https:\/\/abs.twimg.com\/sticky\/default_profile_images\/default_profile_normal.png","id_on_source":"gngdb_rss_bot","tweeter_id":"3395908937","geo":{"lt":null,"ln":null},"followers":11},"tweet_id":"912485339280941056"},{"url":"http:\/\/twitter.com\/helioRocha_\/statuses\/912485487713058817","license":"gnip","citation_ids":[26572550],"posted_on":"2017-09-26T01:14:28+00:00","author":{"name":"Helio Rocha","url":"http:\/\/about.me\/helioRocha","image":"https:\/\/pbs.twimg.com\/profile_images\/894370407205277702\/wj7f8Yg3_normal.jpg","id_on_source":"helioRocha_","tweeter_id":"193464000","geo":{"lt":null,"ln":null},"followers":602},"tweet_id":"912485487713058817"},{"url":"http:\/\/twitter.com\/ibiris\/statuses\/912485827997048832","license":"gnip","citation_ids":[26572550],"posted_on":"2017-09-26T01:15:49+00:00","author":{"name":"Ilias Biris","url":"http:\/\/fi.linkedin.com\/in\/biris","image":"https:\/\/pbs.twimg.com\/profile_images\/1269275702\/biris_LThumb_normal.jpg","description":"Machine learning developer and enthusiast, living in Helsinki. Raising a family, sitting zazen, cycling, cooking and surviving Finland.","id_on_source":"ibiris","tweeter_id":"4203571","geo":{"lt":60.16952,"ln":24.93545,"country":"FI"},"followers":510},"tweet_id":"912485827997048832"},{"url":"http:\/\/twitter.com\/SoEngineering\/statuses\/912485832719773696","license":"gnip","citation_ids":[26572550],"posted_on":"2017-09-26T01:15:50+00:00","author":{"name":"Thorsten Sommer","image":"https:\/\/pbs.twimg.com\/profile_images\/892002973613772800\/IHKa-8mg_normal.jpg","id_on_source":"SoEngineering","tweeter_id":"230157762","geo":{"lt":51.5,"ln":10.5,"country":"DE"},"followers":35},"tweet_id":"912485832719773696"},{"url":"http:\/\/twitter.com\/gngdb_rss_bot\/statuses\/912486242394271744","license":"gnip","citation_ids":[26572550],"posted_on":"2017-09-26T01:17:28+00:00","author":{"name":"gngdb rss bot","image":"https:\/\/abs.twimg.com\/sticky\/default_profile_images\/default_profile_normal.png","id_on_source":"gngdb_rss_bot","tweeter_id":"3395908937","geo":{"lt":null,"ln":null},"followers":11},"tweet_id":"912486242394271744"},{"url":"http:\/\/twitter.com\/dbworld_\/statuses\/912486740845383680","license":"gnip","citation_ids":[26572550],"posted_on":"2017-09-26T01:19:26+00:00","author":{"name":"DBWorld Updates","url":"http:\/\/dbw.tumblr.com\/","image":"https:\/\/pbs.twimg.com\/profile_images\/1330516686\/databaseGlobe_normal.png","description":"Job Ann, post docs, CFP, startups. Topics: DB, IR, Sem Web, Info Integration, HCI, Mobile, ML, AI, Bio, Graphs","id_on_source":"dbworld_","tweeter_id":"187484390","geo":{"lt":null,"ln":null},"followers":419},"tweet_id":"912486740845383680"},{"url":"http:\/\/twitter.com\/helioRocha_\/statuses\/912487039618240513","license":"gnip","citation_ids":[26572550],"posted_on":"2017-09-26T01:20:38+00:00","author":{"name":"Helio Rocha","url":"http:\/\/about.me\/helioRocha","image":"https:\/\/pbs.twimg.com\/profile_images\/894370407205277702\/wj7f8Yg3_normal.jpg","id_on_source":"helioRocha_","tweeter_id":"193464000","geo":{"lt":null,"ln":null},"followers":602},"tweet_id":"912487039618240513"},{"url":"http:\/\/twitter.com\/deep_rl\/statuses\/912496843321434112","license":"gnip","citation_ids":[26572550],"posted_on":"2017-09-26T01:59:35+00:00","author":{"name":"Deep RL","image":"https:\/\/pbs.twimg.com\/profile_images\/703846034959527937\/ygb5ntX5_normal.jpg","description":"Papers about distributed deep and reinforcement learning.","id_on_source":"deep_rl","tweeter_id":"703836179318214656","geo":{"lt":null,"ln":null},"followers":217},"tweet_id":"912496843321434112"},{"url":"http:\/\/twitter.com\/StatsPapers\/statuses\/912506299002187776","license":"gnip","citation_ids":[26572550],"posted_on":"2017-09-26T02:37:09+00:00","author":{"name":"Statistics Papers","url":"http:\/\/arxiv.org\/archive\/stat","image":"https:\/\/pbs.twimg.com\/profile_images\/1149879325\/arxiv_normal.png","description":"New Statistics submissions to http:\/\/arxiv.org (not affiliated with http:\/\/arxiv.org)","id_on_source":"StatsPapers","tweeter_id":"131998399","geo":{"lt":null,"ln":null},"followers":2389},"tweet_id":"912506299002187776"},{"url":"http:\/\/twitter.com\/arxivml\/statuses\/912577858320633857","license":"gnip","citation_ids":[26572550],"posted_on":"2017-09-26T07:21:30+00:00","author":{"name":"\u5348\u5f8c\u306earXiv","image":"https:\/\/pbs.twimg.com\/profile_images\/850909551767371776\/YuZNoCwD_normal.jpg","description":"http:\/\/arXiv.org \u306ecs.NE, cs.LG, cs.AI, cs.CV, cs.CL, stat.ML\u306b\u6295\u7a3f\u3055\u308c\u305f\u6bce\u65e5\u306e\u8ad6\u6587\u3092\u3001\u65e5\u672c\u6642\u9593\u306e\u6b63\u5348\u304b\u308910\u5206\u9593\u9694\u3067\u30c4\u30a4\u30fc\u30c8\u3059\u308bbot\u3067\u3059\u3002\u8a66\u9a13\u904b\u7528\u4e2d\u3002","id_on_source":"arxivml","tweeter_id":"849622895189827585","geo":{"lt":null,"ln":null},"followers":60},"tweet_id":"912577858320633857"},{"url":"http:\/\/twitter.com\/arxiv_flying\/statuses\/912715124976361473","license":"gnip","citation_ids":[26572550],"posted_on":"2017-09-26T16:26:57+00:00","author":{"name":"arxiv_flying","image":"https:\/\/abs.twimg.com\/sticky\/default_profile_images\/default_profile_normal.png","description":"stat.ML, cs.CL, cs.LG","id_on_source":"arxiv_flying","tweeter_id":"756502711621726209","geo":{"lt":null,"ln":null},"followers":424},"tweet_id":"912715124976361473"},{"url":"http:\/\/twitter.com\/muktabh\/statuses\/912882781188890625","license":"gnip","rt":["arxiv_flying"],"citation_ids":[26572550],"posted_on":"2017-09-27T03:33:10+00:00","author":{"name":"Muktabh Mayank","image":"https:\/\/pbs.twimg.com\/profile_images\/731876658307694592\/8h9SO4zU_normal.jpg","description":"cofounder at @ParallelDots, Data Scientist, entrepreneur , sociologist, not the classic nerd..","id_on_source":"muktabh","tweeter_id":"28991794","geo":{"lt":28.4601,"ln":77.02635,"country":"IN"},"followers":705},"tweet_id":"912882781188890625"}],"reddit":[{"title":"[1709.08201] An Optimal Online Method of Selecting Source Policies for Reinforcement Learning","url":"http:\/\/www.reddit.com\/r\/reinforcementlearning\/comments\/72hloi\/170908201_an_optimal_online_method_of_selecting\/","license":"public","citation_ids":[26572550],"posted_on":"2017-09-26T03:00:21+00:00","author":{"name":"PM_ME_FRENCH_WORDS","url":"http:\/\/www.reddit.com\/r\/reinforcementlearning","id_on_source":"reinforcementlearning","followers":155,"subreddit":"Reinforcement Learning"}}]}}