{"altmetric_id":5077409,"counts":{"readers":{"mendeley":13,"citeulike":0,"connotea":0},"total":{"posts_count":2},"twitter":{"unique_users_count":2,"unique_users":["psych2evidence","AV_SP"],"posts_count":2}},"selected_quotes":["A multimodal analysis of startle responses using a variety of physiological, facial speech features"],"citation":{"abstract":"This article presents a multimodal analysis of startle type responses using a variety of physiological, facial, and speech features. These multimodal components of the startle type response reflect complex brain-body reactions to a sudden and intense stimulus. Additionally, the proposed multimodal evaluation of reflexive and emotional reactions associated with the startle eliciting stimuli and underlying neural networks and pathways could be applied in diagnostics of different psychiatric and neurological diseases. Different startle type stimuli can be compared in the strength of their elicitation of startle responses, i.e. their potential to activate stress-related neural pathways, underlying biomarkers and corresponding behavioral reactions.\nAn innovative method for measuring startle type responses using multimodal stimuli and multimodal feature analysis has been introduced. Individual's multimodal reflexive and emotional expressions during startle type elicitation have been assessed by corresponding physiological, speech and facial features on ten female students of psychology. Different startle eliciting stimuli like noise and airblast probes, as well as a variety of visual and auditory stimuli of different valence and arousal levels, based on International Affective Picture System (IAPS) images and\/or sounds from International Affective Digitized Sounds (IADS) database, have been designed and tested. Combined together into more complex startle type stimuli, such composite stimuli can potentiate the evoked response of underlying neural networks, and corresponding neurotransmitters and neuromodulators as well; this is referred to as increased power of response elicitation. The intensity and magnitude of multimodal responses to selected startle type stimuli have been analyzed using effect sizes and medians of dominant multimodal features, i.e. skin conductance, eye blink, head movement, speech fundamental frequency and energy. The significance of the observed effects and comparisons between paradigms were evaluated using one-tailed t-tests and ANOVA methods, respectively. Skin conductance response habituation was analyzed using ANOVA and post hoc multiple comparison tests with the Dunn-\u0160id\u00e1k correction.\nThe results revealed specific physiological, facial and vocal reflexive and emotional responses on selected five stimuli paradigms which included: (1) acoustic startle probes, (2) airblasts, (3) IAPS images, (4) IADS sounds, and (5) image-sound-airblast composite stimuli. Overall, composite and airblast paradigms resulted in the largest responses across all analyzed features, followed by sound and acoustic startle paradigms, while paradigm using images consistently elicited the smallest responses. In this context, power of response elicitation of the selected stimuli paradigms can be described according to the aggregated magnitude of the participants' multimodal responses. We also observed a habituation effect only in skin conductance response to acoustic startle, airblast and sound paradigms.\nThis study developed a system for paradigm design and stimuli generation, as well as real-time multimodal signal processing and feature calculation. Experimental paradigms for monitoring individual responses to stressful startle type stimuli were designed in order to compare the response elicitation power across various stimuli. The developed system, applied paradigms and obtained results might be useful in further research for evaluation of individuals' multimodal responses when they are faced with a variety of aversive emotional distractors and stressful situations.","altmetric_jid":"4f6fa4ea3cf058f6100025d9","authors":["\u0106osi\u0107, Kre\u0161imir","Popovi\u0107, Sini\u0161a","Kukolja, Davor","Dropulji\u0107, Branimir","Ivanec, Dragutin","Tonkovi\u0107, Mirjana"],"doi":"10.1016\/j.cmpb.2016.01.002","first_seen_on":"2016-02-02T12:40:39+00:00","funders":["niehs"],"issns":["1872-7565"],"journal":"Computer Methods & Programs in Biomedicine","last_mentioned_on":1454829063,"links":["http:\/\/www.ncbi.nlm.nih.gov\/pubmed\/26826902?dopt=Abstract","http:\/\/www.ncbi.nlm.nih.gov\/pubmed\/26826902"],"pmid":"26826902","pubdate":"2016-02-02T22:01:11+00:00","publisher_subjects":[{"name":"Biomedical Engineering","scheme":"era"}],"scopus_subjects":["Health Sciences","Medicine","Physical Sciences","Computer Science"],"subjects":["medicalinformatics"],"title":"Multimodal analysis of startle type responses.","type":"article","mendeley_url":"http:\/\/www.mendeley.com\/research\/multimodal-analysis-startle-type-responses"},"altmetric_score":{"score":0.5,"score_history":{"1y":0,"6m":0,"3m":0,"1m":0,"1w":0,"6d":0,"5d":0,"4d":0,"3d":0,"2d":0,"1d":0,"at":0.5},"context_for_score":{"all":{"total_number_of_other_articles":7128274,"mean":6.3030470395816,"rank":5351867,"this_scored_higher_than_pct":13,"this_scored_higher_than":992009,"rank_type":"exact","sample_size":7128274,"percentile":13},"similar_age_3m":{"total_number_of_other_articles":320590,"mean":9.3756288207016,"rank":221479,"this_scored_higher_than_pct":17,"this_scored_higher_than":55343,"rank_type":"exact","sample_size":320590,"percentile":17},"this_journal":{"total_number_of_other_articles":350,"mean":1.6847621776504,"rank":200,"this_scored_higher_than_pct":30,"this_scored_higher_than":106,"rank_type":"exact","sample_size":350,"percentile":30},"similar_age_this_journal_3m":{"total_number_of_other_articles":27,"mean":1.6096153846154,"rank":12,"this_scored_higher_than_pct":37,"this_scored_higher_than":10,"rank_type":"exact","sample_size":27,"percentile":37}}},"demographics":{"poster_types":{"member_of_the_public":2},"users":{"twitter":{"cohorts":{"Members of the public":2}},"mendeley":{"by_status":{"Unspecified":1,"Professor > Associate Professor":1,"Student  > Doctoral Student":1,"Researcher":5,"Student  > Master":3,"Student  > Bachelor":2},"by_discipline":{"Engineering":3,"Psychology":4,"Computer Science":4,"Business, Management and Accounting":1,"Unspecified":1}}},"geo":{"twitter":{"GB":1},"mendeley":{"PT":1}}},"posts":{"twitter":[{"url":"http:\/\/twitter.com\/psych2evidence\/statuses\/694500608984764416","license":"gnip","citation_ids":[5077409],"posted_on":"2016-02-02T12:40:23+00:00","author":{"name":"Psych2 Evidence","image":"https:\/\/pbs.twimg.com\/profile_images\/590651515787993088\/48DTFkEi_normal.jpg","description":"Real-time Evidence-Based Psychiatry Online #ebm #digital #technology #evidence #psychiatry #mentalhealth #futuremedicine Dr Naik @UniofOxford EBHC Student","id_on_source":"psych2evidence","tweeter_id":"3192717557","geo":{"lt":51.75222,"ln":-1.25596,"country":"GB"},"followers":978},"tweet_id":"694500608984764416"},{"url":"http:\/\/twitter.com\/AV_SP\/statuses\/696229670061117444","license":"gnip","citation_ids":[5077409],"posted_on":"2016-02-07T07:11:03+00:00","author":{"name":"AV Speech Processing","url":"http:\/\/avisa.loria.fr\/","image":"https:\/\/pbs.twimg.com\/profile_images\/892275071179382784\/VoVEVad4_normal.jpg","description":"The unofficial account of Auditory-VIsual Speech Association. AV speech references + what interests me https:\/\/goo.gl\/oblTmr","id_on_source":"AV_SP","tweeter_id":"2733383114","geo":{"lt":null,"ln":null},"followers":525},"tweet_id":"696229670061117444"}]}}