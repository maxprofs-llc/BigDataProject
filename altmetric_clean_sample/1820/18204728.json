{"altmetric_id":18204728,"counts":{"readers":{"mendeley":12,"citeulike":0,"connotea":0},"total":{"posts_count":12},"twitter":{"unique_users_count":9,"unique_users":["arxiv_cscv","arxiv_cs_CV","papers___","gngdb_rss_bot","ai_papers","arxiv_org","HubBucket","Rosenchild","Amboinensis"],"posts_count":12}},"selected_quotes":["Robust Depth-based Person Re-identification. (arXiv:1703.09474v1 )","cs.CV: Robust Depth-based Person Re-identification. (arXiv:1703.09474v1 )"],"citation":{"abstract":"Person re-identification (re-id) aims to match people across non-overlapping camera views. So far the RGB-based appearance is widely used in most existing works. However, when people appeared in extreme illumination or changed clothes, the RGB appearance-based re-id methods tended to fail. To overcome this problem, we propose to exploit depth information to provide more invariant body shape and skeleton information regardless of illumination and color change. More specifically, we exploit depth voxel covariance descriptor and further propose a locally rotation invariant depth shape descriptor called Eigen-depth feature to describe pedestrian body shape. We prove that the distance between any two covariance matrices on the Riemannian manifold is equivalent to the Euclidean distance between the corresponding Eigen-depth features. Furthermore, we propose a kernelized implicit feature transfer scheme to estimate Eigendepth feature implicitly from RGB image when depth information is not available. We find that combining the estimated depth features with RGB-based appearance features can sometimes help to better reduce visual ambiguities of appearance features caused by illumination and similar clothes. The effectiveness of our models was validated on publicly available depth pedestrian datasets as compared to related methods for person re-identification.","altmetric_jid":"4f6fa4ed3cf058f610002a5c","arxiv_id":"1703.09474","authors":["Ancong Wu","Wei-Shi Zheng","Jianhuang Lai","A. Wu","W. S. Zheng","J. H. Lai"],"doi":"10.1109\/tip.2017.2675201","first_seen_on":"2017-03-29T00:34:24+00:00","funders":["niehs"],"issns":["1057-7149","1941-0042"],"journal":"IEEE Transactions on Image Processing","last_mentioned_on":1493944963,"links":["https:\/\/arxiv.org\/abs\/1703.09474","https:\/\/arxiv.org\/abs\/1703.09474v1","https:\/\/arxiv.org\/abs\/1703.09474?utm_source=dlvr.it&utm_medium=twitter","http:\/\/ieeexplore.ieee.org\/document\/7864367?reload=true"],"pdf_url":"http:\/\/arxiv.org\/pdf\/1703.09474v1","pmid":"28252397","pubdate":"2017-03-28T09:26:54+00:00","publisher":"IEEE","publisher_subjects":[{"name":"Artificial Intelligence And Image Processing","scheme":"era"},{"name":"Electrical And Electronic Engineering","scheme":"era"},{"name":"Cognitive Science","scheme":"era"}],"scopus_subjects":["Physical Sciences","Computer Science"],"subjects":["medicalinformatics"],"title":"Robust Depth-based Person Re-identification","type":"article","uri":"http:\/\/ieeexplore.ieee.org\/document\/7864367\/","mendeley_url":"http:\/\/www.mendeley.com\/research\/robust-depthbased-person-reidentification"},"altmetric_score":{"score":2.5,"score_history":{"1y":2.5,"6m":2.5,"3m":0,"1m":0,"1w":0,"6d":0,"5d":0,"4d":0,"3d":0,"2d":0,"1d":0,"at":2.5},"context_for_score":{"all":{"total_number_of_other_articles":8160820,"mean":6.9113685834654,"rank":3305790,"this_scored_higher_than_pct":58,"this_scored_higher_than":4797125,"rank_type":"exact","sample_size":8160820,"percentile":58},"similar_age_3m":{"total_number_of_other_articles":239052,"mean":13.243872144437,"rank":91890,"this_scored_higher_than_pct":60,"this_scored_higher_than":145388,"rank_type":"exact","sample_size":239052,"percentile":60},"this_journal":{"total_number_of_other_articles":286,"mean":2.226849122807,"rank":77,"this_scored_higher_than_pct":70,"this_scored_higher_than":202,"rank_type":"exact","sample_size":286,"percentile":70},"similar_age_this_journal_3m":{"total_number_of_other_articles":13,"mean":1.3041666666667,"rank":3,"this_scored_higher_than_pct":76,"this_scored_higher_than":10,"rank_type":"exact","sample_size":13,"percentile":76}}},"demographics":{"poster_types":{"member_of_the_public":9},"users":{"twitter":{"cohorts":{"Members of the public":9}},"mendeley":{"by_status":{"Unspecified":1,"Researcher":1,"Student  > Ph. D. Student":3,"Student  > Master":6,"Other":1},"by_discipline":{"Engineering":1,"Computer Science":10,"Unspecified":1}}},"geo":{"twitter":{"US":2},"mendeley":{"IN":1}}},"posts":{"twitter":[{"url":"http:\/\/twitter.com\/arxiv_cscv\/statuses\/847232123211726848","license":"gnip","citation_ids":[18204728],"posted_on":"2017-03-29T23:40:53+00:00","author":{"name":"arXiv CS-CV","url":"https:\/\/github.com\/ozan\/arxiv-twitter","image":"https:\/\/pbs.twimg.com\/profile_images\/736660587686416385\/V8FO6CoZ_normal.jpg","description":"All recent computer vision articles from http:\/\/arXiv.org","id_on_source":"arxiv_cscv","tweeter_id":"736627781421826048","geo":{"lt":null,"ln":null},"followers":937},"tweet_id":"847232123211726848"},{"url":"http:\/\/twitter.com\/arxiv_cscv\/statuses\/846899829460520963","license":"gnip","citation_ids":[18204728],"posted_on":"2017-03-29T01:40:28+00:00","author":{"name":"arXiv CS-CV","url":"https:\/\/github.com\/ozan\/arxiv-twitter","image":"https:\/\/pbs.twimg.com\/profile_images\/736660587686416385\/V8FO6CoZ_normal.jpg","description":"All recent computer vision articles from http:\/\/arXiv.org","id_on_source":"arxiv_cscv","tweeter_id":"736627781421826048","geo":{"lt":null,"ln":null},"followers":937},"tweet_id":"846899829460520963"},{"url":"http:\/\/twitter.com\/arxiv_cs_CV\/statuses\/846899870958940163","license":"gnip","citation_ids":[18204728],"posted_on":"2017-03-29T01:40:38+00:00","author":{"name":"cs.CV Papers","image":"https:\/\/abs.twimg.com\/sticky\/default_profile_images\/default_profile_normal.png","description":"unofficial updates on arXiv cs.CV (computer science. computer vision) papers","id_on_source":"arxiv_cs_CV","tweeter_id":"4127701032","geo":{"lt":null,"ln":null},"followers":224},"tweet_id":"846899870958940163"},{"url":"http:\/\/twitter.com\/papers___\/statuses\/846894094278320129","license":"gnip","citation_ids":[18204728],"posted_on":"2017-03-29T01:17:41+00:00","author":{"name":"nick","image":"https:\/\/abs.twimg.com\/sticky\/default_profile_images\/default_profile_normal.png","id_on_source":"papers___","tweeter_id":"2964203236","geo":{"lt":null,"ln":null},"followers":28},"tweet_id":"846894094278320129"},{"url":"http:\/\/twitter.com\/arxiv_cscv\/statuses\/847081161771900929","license":"gnip","citation_ids":[18204728],"posted_on":"2017-03-29T13:41:01+00:00","author":{"name":"arXiv CS-CV","url":"https:\/\/github.com\/ozan\/arxiv-twitter","image":"https:\/\/pbs.twimg.com\/profile_images\/736660587686416385\/V8FO6CoZ_normal.jpg","description":"All recent computer vision articles from http:\/\/arXiv.org","id_on_source":"arxiv_cscv","tweeter_id":"736627781421826048","geo":{"lt":null,"ln":null},"followers":937},"tweet_id":"847081161771900929"},{"url":"http:\/\/twitter.com\/arxiv_cscv\/statuses\/846884853018701825","license":"gnip","citation_ids":[18204728],"posted_on":"2017-03-29T00:40:57+00:00","author":{"name":"arXiv CS-CV","url":"https:\/\/github.com\/ozan\/arxiv-twitter","image":"https:\/\/pbs.twimg.com\/profile_images\/736660587686416385\/V8FO6CoZ_normal.jpg","description":"All recent computer vision articles from http:\/\/arXiv.org","id_on_source":"arxiv_cscv","tweeter_id":"736627781421826048","geo":{"lt":null,"ln":null},"followers":937},"tweet_id":"846884853018701825"},{"url":"http:\/\/twitter.com\/gngdb_rss_bot\/statuses\/846883158293393409","license":"gnip","citation_ids":[18204728],"posted_on":"2017-03-29T00:34:13+00:00","author":{"name":"gngdb rss bot","image":"https:\/\/abs.twimg.com\/sticky\/default_profile_images\/default_profile_normal.png","id_on_source":"gngdb_rss_bot","tweeter_id":"3395908937","geo":{"lt":null,"ln":null},"followers":9},"tweet_id":"846883158293393409"},{"url":"http:\/\/twitter.com\/ai_papers\/statuses\/846973226400010242","license":"gnip","citation_ids":[18204728],"posted_on":"2017-03-29T06:32:07+00:00","author":{"name":"AIPapers","image":"https:\/\/pbs.twimg.com\/profile_images\/746736489539768320\/5hQCfxAV_normal.jpg","description":"Twitterbot of #CS papers (focused in #AI, #robotics and #computervision in #arXiv. Curated by @vasanthsarathy","id_on_source":"ai_papers","tweeter_id":"746735316296433664","geo":{"lt":null,"ln":null},"followers":225},"tweet_id":"846973226400010242"},{"url":"http:\/\/twitter.com\/arxiv_org\/statuses\/847355982967562240","license":"gnip","citation_ids":[18204728],"posted_on":"2017-03-30T07:53:04+00:00","author":{"name":"arxiv","url":"http:\/\/arxiv.org","image":"https:\/\/pbs.twimg.com\/profile_images\/752339815002091520\/d403dpBl_normal.jpg","description":"Unofficial bot posting recent scientific paper e-prints every hour, run by @yddt","id_on_source":"arxiv_org","tweeter_id":"751734284092792832","geo":{"lt":null,"ln":null},"followers":1365},"tweet_id":"847355982967562240"},{"url":"http:\/\/twitter.com\/HubBucket\/statuses\/848451664759726080","license":"gnip","rt":["arxiv_org"],"citation_ids":[18204728],"posted_on":"2017-04-02T08:26:55+00:00","author":{"name":"HubBucket","url":"http:\/\/hubbucket.xyz","image":"https:\/\/pbs.twimg.com\/profile_images\/879250880146452481\/GlvLBdAK_normal.jpg","description":"@HubBucket #Technology #Research & #Development | #HumanRights, #CivilRights & #EqualRight for ALL People. Founder & CEO VonVictor V.  @Rosenchild","id_on_source":"HubBucket","tweeter_id":"2742938653","geo":{"lt":40.6501,"ln":-73.94958,"country":"US"},"followers":2771},"tweet_id":"848451664759726080"},{"url":"http:\/\/twitter.com\/Rosenchild\/statuses\/848885115853967360","license":"gnip","rt":["arxiv_org"],"citation_ids":[18204728],"posted_on":"2017-04-03T13:09:17+00:00","author":{"name":"VonVictor Rosenchild","url":"https:\/\/about.me\/rosenchild","image":"https:\/\/pbs.twimg.com\/profile_images\/905469316400689154\/iV3AvhWL_normal.jpg","description":"@HubBucket - Technology Research and Development - R&D Founder & CEO | #Humanitarian | \ud83c\uddfa\ud83c\uddf8U.S. Navy Intelligence #Veteran. | Former CTO, CIO, CISO, etc.","id_on_source":"Rosenchild","tweeter_id":"480875170","geo":{"lt":43.00035,"ln":-75.4999,"country":"US"},"followers":8644},"tweet_id":"848885115853967360"},{"url":"http:\/\/twitter.com\/Amboinensis\/statuses\/860293647769534464","license":"gnip","citation_ids":[18204728],"posted_on":"2017-05-05T00:42:43+00:00","author":{"name":"Amboinensis","image":"https:\/\/pbs.twimg.com\/profile_images\/697108125\/81233_large_normal.jpg","description":"\u67d0Wiki\u306e\u4e2d\u306e\u4eba\u3067\u3059\u3002\u52c9\u5f37\u4f1a\u306e\u6642\u4ee5\u5916\u306f8\u5272\u304f\u3089\u3044\u7121\u76ca\u306atweet\u306a\u306e\u3067\u30d5\u30a9\u30ed\u30fc\u3055\u308c\u308b\u65b9\u306f\u3054\u6ce8\u610f\u3092\u3002","id_on_source":"Amboinensis","tweeter_id":"88118790","geo":{"lt":null,"ln":null},"followers":731},"tweet_id":"860293647769534464"}]}}