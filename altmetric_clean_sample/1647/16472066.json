{"altmetric_id":16472066,"counts":{"readers":{"mendeley":11,"citeulike":0,"connotea":0},"total":{"posts_count":4},"twitter":{"unique_users_count":4,"unique_users":["neuropapersbot","uranus_2","seeingwithsound","annamassus"],"posts_count":4}},"selected_quotes":["Hearing flashes and seeing beeps: Timing audiovisual events Nearly total auditory capture"],"citation":{"abstract":"Many events from daily life are audiovisual (AV). Handclaps produce both visual and acoustic signals that are transmitted in air and processed by our sensory systems at different speeds, reaching the brain multisensory integration areas at different moments. Signals must somehow be associated in time to correctly perceive synchrony. This project aims at quantifying the mutual temporal attraction between senses and characterizing the different interaction modes depending on the offset. In every trial participants saw four beep-flash pairs regularly spaced in time, followed after a variable delay by a fifth event in the test modality (auditory or visual). A large range of AV offsets was tested. The task was to judge whether the last event came before\/after what was expected given the perceived rhythm, while attending only to the test modality. Flashes were perceptually shifted in time toward beeps, the attraction being stronger for lagging than leading beeps. Conversely, beeps were not shifted toward flashes, indicating a nearly total auditory capture. The subjective timing of the visual component resulting from the AV interaction could easily be forward but not backward in time, an intuitive constraint stemming from minimum visual processing delays. Finally, matching auditory and visual time-sensitivity with beeps embedded in pink noise produced very similar mutual attractions of beeps and flashes. Breaking the natural auditory preference for timing allowed vision to take over as well, showing that this preference is not hardwired.","altmetric_jid":"4f6fa5313cf058f6100043e3","authors":["Manuel Vidal"],"doi":"10.1371\/journal.pone.0172028","first_seen_on":"2017-02-16T20:24:54+00:00","funders":["niehs"],"issns":["1932-6203"],"issue":"2","journal":"PLoS ONE","last_mentioned_on":1494410464,"links":["http:\/\/journals.plos.org\/plosone\/article?id=10.1371%2Fjournal.pone.0172028&utm_source=dlvr.it&utm_medium=twitter","http:\/\/journals.plos.org\/plosone\/article?id=10.1371\/journal.pone.0172028","https:\/\/doi.org\/10.1371\/journal.pone.0172028"],"pdf_url":"http:\/\/journals.plos.org\/plosone\/article\/file?id=10.1371\/journal.pone.0172028&type=printable","pmid":"28207786","pubdate":"2017-02-16T00:00:00+00:00","publisher":"Public Library of Science","publisher_subjects":[{"name":"Multidisciplinary","scheme":"era"}],"scopus_subjects":["Life Sciences","Medicine","Health Sciences","Agricultural and Biological Sciences","Biochemistry, Genetics and Molecular Biology"],"startpage":"e0172028","subjects":["medicine","science"],"title":"Hearing flashes and seeing beeps: Timing audiovisual events","type":"article","uri":"http:\/\/dx.plos.org\/10.1371\/journal.pone.0172028","volume":"12","mendeley_url":"http:\/\/www.mendeley.com\/research\/hearing-flashes-seeing-beeps-timing-audiovisual-events"},"altmetric_score":{"score":1.5,"score_history":{"1y":1.5,"6m":1.5,"3m":0,"1m":0,"1w":0,"6d":0,"5d":0,"4d":0,"3d":0,"2d":0,"1d":0,"at":1.5},"context_for_score":{"all":{"total_number_of_other_articles":8183022,"mean":6.92160443679,"rank":3855594,"this_scored_higher_than_pct":50,"this_scored_higher_than":4145374,"rank_type":"exact","sample_size":8183022,"percentile":50},"similar_age_3m":{"total_number_of_other_articles":236702,"mean":13.796646849823,"rank":117522,"this_scored_higher_than_pct":47,"this_scored_higher_than":112219,"rank_type":"exact","sample_size":236702,"percentile":47},"this_journal":{"total_number_of_other_articles":113606,"mean":10.57366242683,"rank":55050,"this_scored_higher_than_pct":47,"this_scored_higher_than":54142,"rank_type":"exact","sample_size":113606,"percentile":47},"similar_age_this_journal_3m":{"total_number_of_other_articles":4321,"mean":11.809050462963,"rank":2045,"this_scored_higher_than_pct":49,"this_scored_higher_than":2136,"rank_type":"exact","sample_size":4321,"percentile":49}}},"demographics":{"poster_types":{"member_of_the_public":4},"users":{"twitter":{"cohorts":{"Members of the public":4}},"mendeley":{"by_status":{"Professor > Associate Professor":2,"Student  > Doctoral Student":1,"Researcher":2,"Student  > Ph. D. Student":2,"Student  > Postgraduate":1,"Lecturer":2,"Lecturer > Senior Lecturer":1},"by_discipline":{"Neuroscience":1,"Psychology":6,"Agricultural and Biological Sciences":1,"Unspecified":3}}},"geo":{"twitter":{"GB":1},"mendeley":{"TR":1,"GB":3}}},"posts":{"twitter":[{"url":"http:\/\/twitter.com\/neuropapersbot\/statuses\/832324825368530944","license":"gnip","citation_ids":[16472066],"posted_on":"2017-02-16T20:24:36+00:00","author":{"name":"Neuroscience Papers","image":"https:\/\/abs.twimg.com\/sticky\/default_profile_images\/default_profile_normal.png","description":"hi there, I am a twitter bot who tweets new papers in neuroscience","id_on_source":"neuropapersbot","tweeter_id":"757895584317440000","geo":{"lt":null,"ln":null},"followers":23},"tweet_id":"832324825368530944"},{"url":"http:\/\/twitter.com\/uranus_2\/statuses\/832566114815090689","license":"gnip","citation_ids":[16472066],"posted_on":"2017-02-17T12:23:24+00:00","author":{"name":"\u30de\u30fc\u30ad\u30e5\u30ea\u30fc\uff12\u4e16","url":"http:\/\/smetc.blog120.fc2.com\/?sp","image":"https:\/\/pbs.twimg.com\/profile_images\/650483455248064512\/EOJq3sZX_normal.png","description":"\u5c11\u306a\u304f\u3068\u3082\u5927\u5b66\u521d\u5e74\u6b21\u307e\u3067\u306f\u5834\u9762\u7dd8\u9ed9\u75c7\uff08\u81ea\u5df1\u8a3a\u65ad\uff09\u3060\u3063\u305f\u7537\u3002Twitter\u307e\u3068\u3081(http:\/\/psychobrain.seesaa.net\/)\u3002 \u6ce8\u610f\u4e8b\u9805\u2460\u8ad6\u6587\u306f\u8981\u7d04\u3057\u304b\u8aad\u3093\u3067\u3044\u306a\u3044\u5834\u5408\u304c\u591a\u3044\u2461\u9593\u9055\u3063\u3066\u3044\u308b\u53ef\u80fd\u6027\u3042\u308a\u2462\u79c1\u306f\u7814\u7a76\u8005\u3067\u306f\u306a\u3044\u3002","id_on_source":"uranus_2","tweeter_id":"253847599","geo":{"lt":null,"ln":null},"followers":3450},"tweet_id":"832566114815090689"},{"url":"http:\/\/twitter.com\/seeingwithsound\/statuses\/832611352120262658","license":"gnip","citation_ids":[16472066],"posted_on":"2017-02-17T15:23:10+00:00","author":{"name":"The vOICe \ud83d\ude0e","url":"http:\/\/www.seeingwithsound.com","image":"https:\/\/pbs.twimg.com\/profile_images\/458734857997139968\/RAoD_AlV_normal.png","description":"The vOICe? Oh I see! Sensory substitution and augmented reality for the blind; artificial vision, neural networks, ... feedback@seeingwithsound.com","id_on_source":"seeingwithsound","tweeter_id":"22481878","geo":{"lt":null,"ln":null},"followers":2121},"tweet_id":"832611352120262658"},{"url":"http:\/\/twitter.com\/annamassus\/statuses\/862246099163152385","license":"gnip","citation_ids":[16472066],"posted_on":"2017-05-10T10:01:04+00:00","author":{"name":"Anna Mas-Casades\u00fas","url":"http:\/\/ow.ly\/Rxod8","image":"https:\/\/pbs.twimg.com\/profile_images\/3388046425\/ea56603726521e661e39e363f4540450_normal.jpeg","description":"PhD #Psychology student at @UoE_Psychology @UniofEdinburgh | #neuroscience #synaesthesia #multisensory #crossmodal","id_on_source":"annamassus","tweeter_id":"22432285","geo":{"lt":55.95206,"ln":-3.19648,"country":"GB"},"followers":667},"tweet_id":"862246099163152385"}]}}