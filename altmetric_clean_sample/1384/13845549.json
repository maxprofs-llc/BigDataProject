{"altmetric_id":13845549,"counts":{"readers":{"mendeley":3,"citeulike":0,"connotea":0},"total":{"posts_count":4},"twitter":{"unique_users_count":4,"unique_users":["PattiAdank","NickBearmanUK","AV_SP","nlp_stories"],"posts_count":4}},"citation":{"abstract":"Unexplained variability in speech recognition outcomes among postlingually deafened adults with cochlear implants (CIs) is an enormous clinical and research barrier to progress. This variability is only partially explained by patient factors (e.g., duration of deafness) and auditory sensitivity (e.g., spectral and temporal resolution). This study sought to determine whether non-auditory neurocognitive skills could explain speech recognition variability exhibited by adult CI users.\nThirty postlingually deafened adults with CIs and thirty age-matched normal-hearing (NH) controls were enrolled.\nParticipants were assessed for recognition of words in sentences in noise and several non-auditory measures of neurocognitive function. These non-auditory tasks assessed global intelligence (problem-solving), controlled fluency, working memory, and inhibition-concentration abilities.\nFor CI users, faster response times during a non-auditory task of inhibition-concentration predicted better recognition of sentences in noise; however, similar effects were not evident for NH listeners.\nFindings from this study suggest that inhibition-concentration skills play a role in speech recognition for CI users, but less so for NH listeners. Further research will be required to elucidate this role and its potential as a novel target for intervention.","authors":["Moberly, Aaron C.","Houston, Derek M.","Castellanos, Irina"],"doi":"10.1002\/lio2.38","first_seen_on":"2016-11-20T17:22:13+00:00","funders":["niehs"],"handles":[],"issns":["2378-8038"],"issue":"6","journal":"Laryngoscope Investigative Otolaryngology","last_mentioned_on":1479671789,"links":["http:\/\/onlinelibrary.wiley.com\/doi\/10.1002\/lio2.38\/full"],"pdf_url":"http:\/\/onlinelibrary.wiley.com\/doi\/10.1002\/lio2.38\/pdf","pmcid":"PMC5467524","pmid":"28660253","pubdate":"2016-11-14T00:00:00+00:00","title":"Non-auditory neurocognitive skills contribute to speech recognition in adults with cochlear implants","type":"article","volume":"1","mendeley_url":"http:\/\/www.mendeley.com\/research\/nonauditory-neurocognitive-skills-contribute-speech-recognition-adults-cochlear-implants"},"altmetric_score":{"score":1.75,"score_history":{"1y":1.75,"6m":0,"3m":0,"1m":0,"1w":0,"6d":0,"5d":0,"4d":0,"3d":0,"2d":0,"1d":0,"at":1.75},"context_for_score":null},"demographics":{"poster_types":{"member_of_the_public":3,"researcher":1},"users":{"twitter":{"cohorts":{"Scientists":1,"Members of the public":3}},"mendeley":{"by_status":{"Professor > Associate Professor":1,"Student  > Ph. D. Student":1,"Student  > Master":1},"by_discipline":{"Medicine and Dentistry":1,"Psychology":1,"Unspecified":1}}},"geo":{"twitter":{"GB":2,"US":1}}},"posts":{"twitter":[{"url":"http:\/\/twitter.com\/PattiAdank\/statuses\/800388737574273024","license":"gnip","citation_ids":[13845549],"posted_on":"2016-11-20T17:22:00+00:00","author":{"name":"Patti Adank","url":"http:\/\/www.speechonthebrain.com","image":"https:\/\/pbs.twimg.com\/profile_images\/901072348295593984\/X_HsSxR-_normal.jpg","description":"Speech scientist at UCL.  I use TMS and fMRI to study how we speak and listen. Tweets reflect my own opinions. I like bikes.","id_on_source":"PattiAdank","tweeter_id":"2494150614","geo":{"lt":51.50853,"ln":-0.12574,"country":"GB"},"followers":1569},"tweet_id":"800388737574273024"},{"url":"http:\/\/twitter.com\/NickBearmanUK\/statuses\/800390779495530496","license":"gnip","rt":["PattiAdank"],"citation_ids":[13845549],"posted_on":"2016-11-20T17:30:07+00:00","author":{"name":"Nick Bearman","url":"http:\/\/nickbearman.me.uk","image":"https:\/\/pbs.twimg.com\/profile_images\/862698737537359874\/SUVDCajz_normal.jpg","description":"Senior GIS Analyst & Course Director @ClearMappingCo & Lect @LivUniGeog; GIS analyst, trainer, cartography, open data, QGIS R ArcGIS https:\/\/t.co\/I2SYDbZqUe","id_on_source":"NickBearmanUK","tweeter_id":"481164619","geo":{"lt":50.20861,"ln":-5.4875,"country":"GB"},"followers":1438},"tweet_id":"800390779495530496"},{"url":"http:\/\/twitter.com\/AV_SP\/statuses\/800422876427886592","license":"gnip","rt":["PattiAdank"],"citation_ids":[13845549],"posted_on":"2016-11-20T19:37:39+00:00","author":{"name":"AV Speech Processing","url":"http:\/\/avisa.loria.fr\/","image":"https:\/\/pbs.twimg.com\/profile_images\/892275071179382784\/VoVEVad4_normal.jpg","description":"The unofficial account of Auditory-VIsual Speech Association. AV speech references + what interests me https:\/\/goo.gl\/oblTmr","id_on_source":"AV_SP","tweeter_id":"2733383114","geo":{"lt":null,"ln":null},"followers":525},"tweet_id":"800422876427886592"},{"url":"http:\/\/twitter.com\/nlp_stories\/statuses\/800427614133452800","license":"gnip","rt":["PattiAdank"],"citation_ids":[13845549],"posted_on":"2016-11-20T19:56:29+00:00","author":{"name":"NLP Stories","image":"https:\/\/pbs.twimg.com\/profile_images\/675784786321891329\/PVScaDr-_normal.jpg","description":"Created by @outpark. Retweeting Natural Language Processing, Deep Learning and A.I. related stories.","id_on_source":"nlp_stories","tweeter_id":"4333795461","geo":{"lt":40.78343,"ln":-73.96625,"country":"US"},"followers":2110},"tweet_id":"800427614133452800"}]}}